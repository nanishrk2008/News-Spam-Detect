{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numpy.random import choice\n",
    "from pandas import read_csv, DataFrame\n",
    "from sklearn.cluster import KMeans\n",
    "import os, sys\n",
    "sys.path.insert(0, 'C:/Users/jjung/Documents/GitHub/News-Spam-Detect/TxtClus/')\n",
    "# sys.path.insert(0, '/home/jz/proj/News-Spam-Detect/TxtClus')\n",
    "from nlp.termWeighting import doc_term_matrix\n",
    "from EstimateK.seqFit import sensitiv\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Clusterings(object):\n",
    "    '''Define a class that encapsulates textual processing tools.'''\n",
    "    def __init__(self, param_dict):\n",
    "        self.__param_dict = param_dict        \n",
    "    \n",
    "    def get_file(self):\n",
    "        '''read csv input into a pandas data frame'''\n",
    "        return read_csv(self.__param_dict['file_loc'], encoding = 'latin1')\n",
    "\n",
    "    def term_weight_matr(self, snippetsArr):\n",
    "        '''compute a document-term matrix based on a collection of text documents'''\n",
    "        return doc_term_matrix(snippetsArr, self.__param_dict)\n",
    "    \n",
    "    def resample(self, df, NUM_BOOTSTRAPS = 3):\n",
    "        bootstraps = [None] * NUM_BOOTSTRAPS\n",
    "        for bootI in range(NUM_BOOTSTRAPS):  \n",
    "            bootstraps[bootI] = df.sample(frac=1/NUM_BOOTSTRAPS, replace=True)\n",
    "        return bootstraps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Pass in settings to instantiate a Clusterings object called vecSpaceMod1:\n",
    "    vecSpaceMod = Clusterings({'file_loc': sys.path[0] + '/Input/newsSample.csv',\n",
    "                               'tf_dampen': True,\n",
    "                               'common_word_pct': 1,\n",
    "                               'rare_word_pct': 1,\n",
    "                               'dim_redu': False})\n",
    "    news = vecSpaceMod.get_file() # Load csv file into data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    # Take 3 bootstrap sub-samples for faster, bagged kmeans fits:\n",
    "    bstraps = vecSpaceMod.resample(news)\n",
    "    # Compute the Term Frequency Inverse Document Frequency matrix based on news headlines:    \n",
    "    metrics_curves = [sensitiv(vecSpaceMod.term_weight_matr(bstrap.TITLE)) for bstrap in bstraps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    tot_metrics = reduce(lambda df1, df2: df1.add(df2), metrics_curves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         2         3         4         5         6         7         8   \\\n",
      "0  0.277934  0.426601  0.544220  0.678488  0.687874  0.796363  0.844935   \n",
      "1  8.450164  7.931397  8.045731  7.930026  7.707352  7.558391  7.737740   \n",
      "\n",
      "         9         10        11      ...              21         22  \\\n",
      "0  0.937884  0.900487  1.002187      ...        1.068558   1.028418   \n",
      "1  7.826602  7.622491  8.087132      ...       14.835294  18.273591   \n",
      "\n",
      "          23            24            25            26            27  \\\n",
      "0   0.990291  9.439555e-01  9.181263e-01  9.080379e-01  9.135929e-01   \n",
      "1  27.138473  1.904242e+32  1.904242e+32  1.904242e+32  1.904242e+32   \n",
      "\n",
      "             28            29            30  \n",
      "0  8.709677e-01  8.709677e-01  8.709677e-01  \n",
      "1  1.904242e+32  1.904242e+32  1.904242e+32  \n",
      "\n",
      "[2 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "    print(tot_metrics)\n",
    "#     def add_df(X1, X2):\n",
    "#         return sensitiv(X1).add(sensitiv(X2))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    df = DataFrame({'predictedCluster': KMeans(17).fit(X1).labels_, \n",
    "                    'document': term_weight_obj['samp']}).sort_values(by='predictedCluster')\n",
    "    \n",
    "    print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

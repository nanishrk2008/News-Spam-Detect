1. Use BM25F: http://www.staff.city.ac.uk/~sb317/papers/foundations_bm25_review.pdf (p363-367)
	BM25-tf = TF_ij(K_1 + 1) / [TF_ij + K_1 * ((1-b) + b*DL_i/avgDL)]  
	
2. Buckshot & Fractionation proposed in Scatter/Gather: Constant-time interaction costs for Scatter/Gather navigation through a cluster hierarchy are achieved by precomputing a cluster hierarchy to be used in Scatter/Gather interaction[3]. The off-line pre-computation uses linear-time algorithms and summarizes document clusters by meta-documents containing profiles of topical words and the most typical titles. These topical words and typical titles are also used to present users a summary of the documents in a cluster. Topical words are those that occur most frequently in a cluster, and typical titles are those with the highest similarity to a centroid of the cluster. Together, the topical words and typical titles form a cluster digest.

3a. MULTI-WAY CLUSTERING:
* Bekkerman et al. [17]; [12, 30, 40, 140, etc.]; [72]	
* MULTI-VIEW LEARNING via Kernel Canonical Correlation Analysis (http://www.cs.utah.edu/~piyush/recent/rai11socialtist.pdf)

3b. BookmarkTreeNode properties: dateAdded, parentId

4. Cluster Labeling, where predictors might be: frequently overlapping phrase, high no. of words, semantic/POS rules, and distance to centroid: 
	* http://nlp.stanford.edu/IR-book/html/htmledition/cluster-labeling-1.html
	* shared salient phrases discovery
	* http://www.cs.cmu.edu/~callan/Papers/dgo06-puck.pdf
	* http://www.aaai.org/ocs/index.php/AAAI/AAAI10/paper/download/1730/2034
	* In STC, final clusters' labels come from sorting its base-cluster labels by their frequencies therein.  

5. Information Visualization: 
* http://people.ischool.berkeley.edu/~hearst/research/infovis.html
* Retrieving the most interesting clusters to display to users can incorporate a separate score based on cluster characteristics like labels, sizes, word-frequencies. 
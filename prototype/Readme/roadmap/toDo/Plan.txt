/*** TO DO LIST ***/
- start by setting normalization parameter to be 100%
- algorithm could be made more efficient by 1) find set of all unique words and 2) count the number of occurences of each word within each document
- systematize all steps, identify the parameters of each step, brainstorm how to optimize them together

** 1st ORDER IMPROVEMENTS TO k-means:
  + test cosine distance vs euclideanDistance in figue.js. Other similarity measures: Jaccard, Dice Coefficient, the Overlap Coefficient (defined by Rijsbergen).
  + k-means++

** IMPROVEMENTS TO MAKE IT FAST:
  + A less aggressive SVD followed by k-means shown to improve over strictly the latter. 
  + Runtime Optimization: Cache function evaluations

** 2nd ORDER IMPROVEMENTS:
  + Pre-conditioning â€“ remove outliers before running kmeans--how? Or, use medoids to reduce influence of outlier.

** MODEL TUNING & TESTING STRATEGY:
  Step 2, With the best metric in hand, apply particle swarm to tune for optimality. 
  Step 3, Tune the weights in BM25 using randomly simulated datasets.